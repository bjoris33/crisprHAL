# models.py for Benchmarking

''' # Replaced by GPU activation code
import numpy as np
import pandas as p
import tensorflow as tf
import tensorflow.keras as k
from tensorflow.keras.layers import Dropout, MaxPooling1D, Dropout
from sklearn.model_selection import train_test_split, KFold
from Bio.SeqUtils import MeltingTemp as mt  
from scipy.stats import spearmanr
from statistics import stdev
import os
import sys

os.environ["CUDA_VISIBLE_DEVICES"] = "1" 
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
'''

import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
os.environ["TF_GPU_ALLOCATOR"] = "cuda_malloc_async" # may need: export TF_GPU_ALLOCATOR=cuda_malloc_async

import tensorflow as tf
import gc # ADDED TO THE PROGRAM TO POTENTIALLY PREVENT GPU MEMORY COLLAPSE... LETS SEE IF IT WORKS!!!

import numpy as np
import pandas as p
import tensorflow.keras as k
from tensorflow.keras.layers import Dropout, MaxPooling1D, Dropout
from sklearn.model_selection import train_test_split, KFold
from Bio.SeqUtils import MeltingTemp as mt
from scipy.stats import spearmanr
from statistics import stdev
import sys

import encoder as e


#** NEW SECTION ATTMPTING TO RESTRICT GPU MEMORY USAGE **

gpus = tf.config.list_physical_devices('GPU')
if gpus:
  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
  try:
    tf.config.set_logical_device_configuration(
        gpus[0],
        [tf.config.LogicalDeviceConfiguration(memory_limit=3072)]) # WITH 4 models running at 2048MiB/run, the memory limit was reached... trying again with 3072MiB/run (4096MiB was occasionally exceeded making it potentially problematic to run out of memory...)
    # WITH memory_limit at 2048, crisprHAL is using 2236MiB to train the eSpCas9 model with limited slowdown (~10s/epoch)
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
  except RuntimeError as e:
    # Virtual devices must be set before GPUs have been initialized
    print(e)

# ^ NEW SECTION TO RESTRICT GPU MEMORY USAGE ^ *


gpu_available = tf.test.is_gpu_available()
if gpu_available: print("Available")
else: print("Not available")


global outputfile, sequencelength, transferlearning, basename, tlname, basedata, tldata, testsets_X, testsets_y, Xtrain, Xtest, ytrain, ytest, Xtrain_raw, Xtest_raw, Xtl, Xtl_raw, ytl, sacas9_noT, sacas9_short
sequencelength=0

# NEED TO IMPLEMENT THIS SOMEHOW
sacas9_noT=False
sacas9_short=False

# Conversion of input nucleotide sequences (ACGT-format) into binary values -- one-hot encoding
def convert_base(arrayinput):
    arrayoutput = []
    for sequence in arrayinput:
        onehotencoding = []
        for i in range(len(sequence)):
            if sequence[i].upper() == "A":
                onehotencoding.append([1,0,0,0])
            elif sequence[i].upper() == "C":
                onehotencoding.append([0,1,0,0])
            elif sequence[i].upper() == "G":
                onehotencoding.append([0,0,1,0])
            elif sequence[i].upper() == "T":
                onehotencoding.append([0,0,0,1])
            elif sequence[i].upper() == "N":
                onehotencoding.append([0,0,0,0])
        arrayoutput.append(np.array(onehotencoding))
    return np.array(arrayoutput)

# Processing the input data file
def process_input(filepath,delimiter=",",nosplit=False):
    global basedata, tldata, sacas9_noT, sacas9_short
    '''
    # Read in from file
    # Convert strings to one hot encodings
    # Return numpy arrays of the one hot encoded sequences and the corresponding y-values
    '''
    print(str(sacas9_noT))
    print(str(sacas9_short))
    Xset = []
    Yset = []
    firstline = True
    global sequencelength
    fileinput = open(filepath,"r")
    for line in fileinput:
        if firstline:
            firstline=False
        elif delimiter in line:
            line = line.split(delimiter)
            #if limiter: line[0] = line[0][limiterstart:limiterend]
            if sequencelength==0:
                if ("SaCas9" in basedata or "SaCas9" in tldata) and sacas9_short:
                    sequencelength=len(line[0])-1
                else:
                    sequencelength=len(line[0])
                print("Sequence length set to: " + str(sequencelength))
            if "SaCas9" not in basedata or sacas9_noT==False or (sacas9_noT and line[0][26] != "T"):
                if ("SaCas9" in basedata or "SaCas9" in tldata) and sacas9_short:
                    Xset.append(line[0][0:26])
                else:
                    Xset.append(line[0])
                Yset.append(float(line[1].strip("\n")))
    Xset = np.array(Xset)
    Yset = np.array(Yset)
    if nosplit == False:
        Xtrain, Xtest, ytrain, ytest = train_test_split(Xset, Yset,test_size=0.2,random_state=1)
        Xtrain_conv = convert_base(Xtrain)
        #print(Xtrain[0])
        #print(Xtrain_conv[0])
        Xtest_conv = convert_base(Xtest)
        #return tf.convert_to_tensor(Xtrain_conv), Xtest_conv, ytrain, ytest, Xtrain, Xtest # FAILS FOR CROSS VALIDATION DATA SPLITTING
        return Xtrain_conv, Xtest_conv, ytrain, ytest, Xtrain, Xtest
    else:
        X_conv = convert_base(Xset)
        #return tf.convert_to_tensor(X_conv), Yset, Xset # FAILS FOR CROSS VALIDATION DATA SPLITTING
        return X_conv, Yset, Xset
    
def aitchison_loss_function(): # TO BE DONE
    return

def crisprHAL(epochs, tlepochs=0, drop_rate=0.3, CNN_filters=128, window_size=3, CNN_drop=0.3, conv1D_padding="same", CNN_dense1=128, CNN_dense2=64, maxpool1D_padding="same", RNN_size=128, RNN_dense1=128, RNN_dense2=64, CNN_RNN_drop=0.3, unfreezing=[17,21,27,33,34,35]):
    
    global outputfile, sequencelength, transferlearning, basename, tlname, testsets_X, testsets_y, Xtrain, Xtest, ytrain, ytest, Xtest_raw, Xtl, ytl
    
    i = k.Input(shape=(sequencelength,4), name="Input")

    # Multi-layer CNN
    c1 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c1")(i)
    l1 = k.layers.LeakyReLU(name="l1")(c1)
    p1 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p1")(l1)
    dr1 = Dropout(CNN_drop, name="dr1")(p1)

    c2 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c2")(dr1)
    l2 = k.layers.LeakyReLU(name="l2")(c2)
    p2 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p2")(l2)
    dr2 = Dropout(CNN_drop, name="dr2")(p2)

    c3 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c3")(dr2)
    l3 = k.layers.LeakyReLU(name="l3")(c3)
    p3 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p3")(l3)
    dr3 = Dropout(CNN_drop, name="dr3")(p3)
    
    c4 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c4")(dr3)
    l4 = k.layers.LeakyReLU(name="l4")(c4)
    p4 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p4")(l4)
    dr4 = Dropout(CNN_drop, name="dr4")(p4)

    f = k.layers.Flatten(name="f")(dr4)

    d1 = k.layers.Dense(CNN_dense1, name="d1")(f)
    ld1 = k.layers.LeakyReLU(name="ld1")(d1)
    drd1 = Dropout(CNN_drop, name="drd1")(ld1)
    d2 = k.layers.Dense(CNN_dense2, name="d2")(drd1)
    ld2 = k.layers.LeakyReLU(name="ld2")(d2)
    drd2 = Dropout(CNN_drop, name="drd2")(ld2)
    x_1d_o = k.layers.Dense(1, name="x_1d_o")(drd2)

    # Bidirectional Gated Recurrent Unit Branch
    r1 = k.layers.Bidirectional(k.layers.GRU(RNN_size, kernel_initializer='he_normal', dropout=drop_rate, recurrent_dropout=0.2), name="r1")(dr1)
    
    f_LSTM = k.layers.Flatten(name="f_LSTM")(r1)
    
    d1_LSTM = k.layers.Dense(RNN_dense1, name="d1_LSTM")(f_LSTM)
    ld1_LSTM = k.layers.LeakyReLU(name="ld1_LSTM")(d1_LSTM)
    drd1_LSTM = Dropout(CNN_RNN_drop, name="drd1_LSTM")(ld1_LSTM)
    d2_LSTM = k.layers.Dense(RNN_dense2, name="d2_LSTM")(drd1_LSTM)
    ld2_LSTM = k.layers.LeakyReLU(name="ld2_LSTM")(d2_LSTM)
    drd2_LSTM = Dropout(CNN_RNN_drop, name="drd2_LSTM")(ld2_LSTM)
    x_LSTM_o = k.layers.Dense(1, name="x_LSTM_o")(drd2_LSTM)
    
    # Concatenated Output Layers
    o_c = k.layers.concatenate([x_1d_o,x_LSTM_o], axis=1, name="o_c")
    o = k.layers.Dense(1, activation="linear", name="o")(o_c)

    # Model Initiation
    m = k.Model(inputs=i, outputs=o)
    compile_options={"optimizer": "adam", "loss": "mean_squared_error"}
    m.compile(**compile_options)

    if transferlearning==False:
        m.summary()
        bestscore = 0.0
        for i in range(0,epochs):
            m.fit(Xtrain,ytrain,epochs=1,batch_size=32,verbose=1) # SET BATCH SIZE AS 32 FOR KEVIN TESTS *****
            testset_score = spearmanr(m.predict(Xtest,verbose=0),ytest,axis=0)[0]
            if testset_score > bestscore:
                bestscore = testset_score
                m.save("model_saves/" + basename + ".h5")
            result = str(str(i+1) + "\tNA\t")
            result = result + "\t" + str(testset_score) + "\tNA"
            for ii in range(0,len(testsets_X)):
                result = result + "\t" + str(spearmanr(m.predict(testsets_X[ii],verbose=0),testsets_y[ii],axis=0)[0])
            print(result)
            outputfile.write(result + "\n")
    
    # NEED TO ADD IN TRANSFER LEARNING OPTION
    else:
        kf = KFold(n_splits=5, shuffle=True, random_state=1)
        '''testset_epoch_results = {}
        for epoch in range(0,tlepochs):
            testset_epoch_results[epoch] = {}
            testset_epoch_results[epoch]["cv_testset"] = []
            testset_epoch_results[epoch]["basedatatestset"] = []
            for dataset in range(0,len(testsets_X)):
                testset_epoch_results[epoch]["testset" + str(dataset)] = []
        '''
        kfold_num = 0
        for train_index, test_index in kf.split(Xtl):
            kfold_num+=1
            cvX_train, cvX_test = Xtl[train_index], Xtl[test_index]
            cvy_train, cvy_test = ytl[train_index], ytl[test_index]
            m = k.models.load_model("model_saves/" + basename + ".h5")
            unfreeze = unfreezing
            for i in range(0,len(m.layers)):
                if i not in unfreeze:
                    m.layers[i].trainable = False
            m.compile(**compile_options)
            if kfold_num==1: m.summary()
            print("Base model prediction: " + str(spearmanr(m.predict(cvX_test, verbose=1),cvy_test)[0])) # ADDED FOR TESTING
            for i in range(0,tlepochs):
                m.fit(cvX_train, cvy_train, epochs=1, batch_size=32, verbose=0) # UPDATED BATCH SIZE TO 32 FROM 20 FOR KEVIN TESTS *****
                basetest_score = spearmanr(m.predict(Xtest,verbose=0),ytest,axis=0)[0]
                testset_score = spearmanr(m.predict(cvX_test,verbose=0),cvy_test,axis=0)[0]
                result = str(str(i+1) + "\t" + str(len(unfreezing)) + "-" + str(kfold_num) + "\t")
                result = result + "\t" + str(basetest_score) + "\t" + str(testset_score)
                for ii in range(0,len(testsets_X)):
                    result = result + "\t" + str(spearmanr(m.predict(testsets_X[ii],verbose=0),testsets_y[ii],axis=0)[0])
                print(result)
                outputfile.write(result + "\n")
    
    k.backend.clear_session()

def CAE(): # TO BE DONE
    k.backend.clear_session()

def CNN(epochs, tlepochs=0, CNN_filters=128, window_size=3, CNN_drop=0.3, conv1D_padding="same", CNN_dense1=128, CNN_dense2=64, maxpool1D_padding="same", unfreezelabel="A", unfreezing=[0]): # TO BE DONE
    
    global outputfile, sequencelength, transferlearning, basename, tlname, testsets_X, testsets_y, Xtrain, Xtest, ytrain, ytest, Xtest_raw, Xtl, ytl
    
    i = k.Input(shape=(sequencelength,4), name="Input")

    # Multi-layer CNN
    c1 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c1")(i)
    l1 = k.layers.LeakyReLU(name="l1")(c1)
    p1 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p1")(l1)
    dr1 = Dropout(CNN_drop, name="dr1")(p1)

    c2 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c2")(dr1)
    l2 = k.layers.LeakyReLU(name="l2")(c2)
    p2 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p2")(l2)
    dr2 = Dropout(CNN_drop, name="dr2")(p2)

    c3 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c3")(dr2)
    l3 = k.layers.LeakyReLU(name="l3")(c3)
    p3 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p3")(l3)
    dr3 = Dropout(CNN_drop, name="dr3")(p3)
    
    c4 = k.layers.Conv1D(CNN_filters,window_size,padding=conv1D_padding, name="c4")(dr3)
    l4 = k.layers.LeakyReLU(name="l4")(c4)
    p4 = MaxPooling1D(pool_size=2,padding=maxpool1D_padding, name="p4")(l4)
    dr4 = Dropout(CNN_drop, name="dr4")(p4)

    f = k.layers.Flatten(name="f")(dr4)

    d1 = k.layers.Dense(CNN_dense1, name="d1")(f)
    ld1 = k.layers.LeakyReLU(name="ld1")(d1)
    drd1 = Dropout(CNN_drop, name="drd1")(ld1)
    d2 = k.layers.Dense(CNN_dense2, name="d2")(drd1)
    ld2 = k.layers.LeakyReLU(name="ld2")(d2)
    drd2 = Dropout(CNN_drop, name="drd2")(ld2)
    o = k.layers.Dense(1, activation="linear", name="o")(drd2)

    # Model Initiation
    m = k.Model(inputs=i, outputs=o)
    compile_options={"optimizer": "adam", "loss": "mean_squared_error"}
    m.compile(**compile_options)

    if transferlearning==False:
        m.summary()
        bestscore = 0.0
        for i in range(0,epochs):
            m.fit(Xtrain,ytrain,epochs=1,batch_size=32,verbose=1)
            testset_score = spearmanr(m.predict(Xtest,verbose=0),ytest,axis=0)[0]
            if testset_score > bestscore:
                bestscore = testset_score
                m.save("model_saves/" + basename + ".h5")
            result = str(str(i+1) + "\tNA\t")
            result = result + "\t" + str(testset_score) + "\tNA"
            for ii in range(0,len(testsets_X)):
                result = result + "\t" + str(spearmanr(m.predict(testsets_X[ii],verbose=0),testsets_y[ii],axis=0)[0])
            print(result)
            outputfile.write(result + "\n")
    
    # NEED TO ADD IN TRANSFER LEARNING OPTION
    else:
        kf = KFold(n_splits=5, shuffle=True, random_state=1)
        kfold_num = 0
        for train_index, test_index in kf.split(Xtl):
            kfold_num+=1
            cvX_train, cvX_test = Xtl[train_index], Xtl[test_index]
            cvy_train, cvy_test = ytl[train_index], ytl[test_index]
            m = k.models.load_model("model_saves/" + basename + ".h5")
            unfreeze = unfreezing
            for i in range(0,len(m.layers)):
                if i not in unfreeze:
                    m.layers[i].trainable = False
            m.compile(**compile_options)
            if kfold_num==1: m.summary()
            print("Base model prediction: " + str(spearmanr(m.predict(cvX_test, verbose=1),cvy_test)[0])) # ADDED FOR TESTING
            for i in range(0,tlepochs):
                m.fit(cvX_train, cvy_train, epochs=1, batch_size=20, verbose=0)
                basetest_score = spearmanr(m.predict(Xtest,verbose=0),ytest,axis=0)[0]
                testset_score = spearmanr(m.predict(cvX_test,verbose=0),cvy_test,axis=0)[0]
                result = str(str(i+1) + "\t" + str(len(unfreezing)) + "-" + str(kfold_num) + "\t")
                result = result + "\t" + str(basetest_score) + "\t" + str(testset_score)
                for ii in range(0,len(testsets_X)):
                    result = result + "\t" + str(spearmanr(m.predict(testsets_X[ii],verbose=0),testsets_y[ii],axis=0)[0])
                print(result)
                outputfile.write(result + "\n")
            gc.collect()
    k.backend.clear_session()

def RNN(): # TO BE DONE
    k.backend.clear_session()

def MHA(): # TO BE DONE
    k.backend.clear_session()



# Command line input format is: python models.py modelname guoscale datatype datascore basedata baseepochs (option: tldata) (option: tlepochs)
# ie: python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_eSpCas9 50 Citro_TevSpCas9 20

transferlearning = False
modelname = sys.argv[1] # crisprHAL, CAE, CNN, RNN, MHA, etc...
guoscale = sys.argv[2] # True for Guo base data, False for all same data
datatype = sys.argv[3] # ALDEx_Standard, ALDEx_Scale, ALDEx_Entropy
datascore = sys.argv[4] # diffbtw, effect, raball
basedata = sys.argv[5] # ie: Guo_eSpCas9, Guo_SpCas9, Citro_TevSpCas9, etc.
baseepochs = int(sys.argv[6])

if "SaCas9" in basedata:
    if "noT" in modelname: sacas9_noT=True
    if "short" in modelname: sacas9_short=True

# Read in and process base model data
if "Guo" in basedata and guoscale==True: Xtrain, Xtest, ytrain, ytest, Xtrain_raw, Xtest_raw = process_input("alldata/GuoScore/GuoScore/" + basedata + "/" + basedata + ".csv",",",False)
else: Xtrain, Xtest, ytrain, ytest, Xtrain_raw, Xtest_raw = process_input("alldata/" + datatype + "/" + datascore + "/" + basedata + "/" + basedata + ".csv",",",False)

# Read in and process transfer learning data (if used)
if len(sys.argv) > 7:
    tldata = sys.argv[7] # ie: pTox_TevSpCas9, Citro_TevSpCas9, Guo_SpCas9_Unique, etc.
    tlepochs = int(sys.argv[8])
    transferlearning = True
    if "Guo" in tldata and guoscale==True: Xtl, ytl, Xtl_raw = process_input("alldata/GuoScore/GuoScore/" + tldata + "/" + tldata + ".csv",",",True)
    else: Xtl, ytl, Xtl_raw = process_input("alldata/" + datatype + "/" + datascore + "/" + tldata + "/" + tldata + ".csv",",",True)
else:
    tldata = "NULL"
    tlepochs=0

# Open output file...
tlname = "NA"
basename = str("basetests/" + modelname + guoscale + datatype + datascore + basedata + str(baseepochs))
if transferlearning:
    tlname = str("tltests/" + modelname + guoscale + datatype + datascore + basedata + str(baseepochs) + tldata + str(tlepochs))
    outputfile = open(tlname + ".tsv","w+")
else: outputfile = open(basename + ".tsv","w+")

# Load the data...
print("\nLoaded model data, now loading testing data.\n")
if "SaCas9" not in basedata:
    if datatype.lower() == "aldex_standard" and datascore.lower() == "diffbtw":
        datasets = ["Guo_eSpCas9","Guo_eSpCas9_Unique","Guo_SpCas9","Guo_SpCas9_Unique","Citro_TevSpCas9","KatG_TevSpCas9","pTox_SpCas9","pTox_TevSpCas9"]
    else:
        datasets = ["Guo_eSpCas9","Guo_eSpCas9_Unique","Guo_SpCas9","Guo_SpCas9_Unique","Citro_TevSpCas9","pTox_KatG_SpCas9","pTox_KatG_TevSpCas9","pTox_SpCas9","pTox_TevSpCas9"]
else:
    datasets = ["Citro_TevSaCas9","pTox_TevSaCas9"]
datasets.remove(basedata)
testsets_X = []
testsets_y = []
for i in range(0,len(datasets)):
    temp_X, temp_y, temp_X_raw = process_input("alldata/" + datatype + "/" + datascore + "/" + datasets[i] + "/" + datasets[i] + ".csv",",",True)
    testsets_X.append(temp_X)
    testsets_y.append(temp_y)
    print("Dataset: " + datasets[i] + " loaded with total sgRNAs: " + str(len(temp_X)) + " and scores: " + str(len(temp_y)))
    if "Guo" in datasets[i]:
        temp_X, temp_y, temp_X_raw = process_input("alldata/GuoScore/GuoScore/" + datasets[i] + "/" + datasets[i] + ".csv",",",True)
        testsets_X.append(temp_X)
        testsets_y.append(temp_y)
        print("Dataset: " + datasets[i] + " loaded with total sgRNAs: " + str(len(temp_X)) + " and scores: " + str(len(temp_y)))
    ''' # FORMER METHOD (DID NOT INCLUDE ALDEx and GUO SCORE FOR GUO DATA)
    if "Guo" in datasets[i] and guoscale==True:
        temp_X, temp_y, temp_X_raw = process_input("alldata/GuoScore/GuoScore/" + datasets[i] + "/" + datasets[i] + ".csv",",",True)
    else:
        temp_X, temp_y, temp_X_raw = process_input("alldata/" + datatype + "/" + datascore + "/" + datasets[i] + "/" + datasets[i] + ".csv",",",True)
    testsets_X.append(temp_X)
    testsets_y.append(temp_y)
    print("Dataset: " + datasets[i] + " loaded with total sgRNAs: " + str(len(temp_X)) + " and scores: " + str(len(temp_y)))'''

print("Total datasets, X-sets: " + str(len(testsets_X)) + ", Y-sets: " + str(len(testsets_y)))


if transferlearning: outputfile.write("Epoch\tCVFold\t" + basedata + "_testset\t" + tldata + "_cv_test")
else: outputfile.write("Epoch\tNoTLorCV\t" + basedata + "_testset\tno_tl")
for dataset in datasets:
    outputfile.write("\t" + dataset)
    if "Guo" in dataset:
        outputfile.write("\t" + dataset + "_GuoScore")
outputfile.write("\n")

#if transferlearning: outputfile = open("tltests/" + modelname + guoscale + datatype + datascore + basedata + str(baseepochs) + tldata + str(tlepochs) + ".tsv","a")
#else: outputfile = open("basetests/" + modelname + guoscale + datatype + datascore + basedata + str(baseepochs) + ".tsv","a")

# Call the model...
print("\nBeginning model test with model: " + modelname + " with 80% training sgRNAs and scores: " + str(len(Xtrain)) + " " + str(len(ytrain)) + " and 20% test sgRNAs and scores: " + str(len(Xtest)) + " " + str(len(ytest))  +"\n")

'''
crisprHAL layers to unfreeze:
-RNN Only
[17,21,27,33,34,35]
-CNN (and RNN) Branch Unfreezing Options
[1,5,9,13,20,26,32,17,21,27,33,34,35]
[5,9,13,20,26,32,17,21,27,33,34,35]
[9,13,20,26,32,17,21,27,33,34,35]
[13,20,26,32,17,21,27,33,34,35]
[20,26,32,17,21,27,33,34,35]
[26,32,17,21,27,33,34,35]
[32,17,21,27,33,34,35]
'''
if modelname=="crisprHAL" and transferlearning==True:
    crisprHAL(baseepochs,tlepochs,unfreezing=[17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[1,5,9,13,20,26,32,17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[5,9,13,20,26,32,17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[9,13,20,26,32,17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[13,20,26,32,17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[20,26,32,17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[26,32,17,21,27,33,34,35])
    crisprHAL(baseepochs,tlepochs,unfreezing=[32,17,21,27,33,34,35])
elif "crisprHAL" in modelname:
    crisprHAL(baseepochs)



outputfile.close()

'''
# Script right now (basic)
# ALDEx_Standard, ALDEx_Scale, ALDEx_Entropy
# diffbtw, effect, raball
# Guo_eSpCas9 Guo_SpCas9 Guo_eSpCas9_Unique Guo_SpCas9_Unique Citro_TevSpCas9 pTox_TevSpCas9


# nohup ./run_ALDEx_Standard_base_models.sh > run_ALDEx_Standard_base_models.out 2>&1 &
# 35480; run with save: 1460538
# run_ALDEx_Standard_base_models.sh

python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Standard diffbtw pTox_TevSpCas9 50

python models.py crisprHAL False ALDEx_Standard effect Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Standard effect Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Standard effect Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Standard effect Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Standard effect Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Standard effect pTox_TevSpCas9 50

python models.py crisprHAL False ALDEx_Standard raball Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Standard raball Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Standard raball Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Standard raball Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Standard raball Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Standard raball pTox_TevSpCas9 50


# nohup ./run_ALDEx_Scale_base_models.sh > run_ALDEx_Scale_base_models.out 2>&1 &
# 36198; run with save: 1460737
# run_ALDEx_Scale_base_models.sh

python models.py crisprHAL False ALDEx_Scale diffbtw Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Scale diffbtw Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Scale diffbtw Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Scale diffbtw Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Scale diffbtw Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Scale diffbtw pTox_TevSpCas9 50

python models.py crisprHAL False ALDEx_Scale effect Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Scale effect Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Scale effect Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Scale effect Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Scale effect Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Scale effect pTox_TevSpCas9 50

python models.py crisprHAL False ALDEx_Scale raball Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Scale raball Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Scale raball Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Scale raball Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Scale raball Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Scale raball pTox_TevSpCas9 50


# nohup ./run_ALDEx_Entropy_base_models.sh > run_ALDEx_Entropy_base_models.out 2>&1 &
# 36915; run with save: 1460932

# run_ALDEx_Entropy_base_models.sh

python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Entropy diffbtw Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Entropy diffbtw pTox_TevSpCas9 50

python models.py crisprHAL False ALDEx_Entropy effect Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Entropy effect Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Entropy effect Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Entropy effect Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Entropy effect Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Entropy effect pTox_TevSpCas9 50

python models.py crisprHAL False ALDEx_Entropy raball Guo_eSpCas9 50
python models.py crisprHAL False ALDEx_Entropy raball Guo_SpCas9 50
python models.py crisprHAL False ALDEx_Entropy raball Guo_eSpCas9_Unique 50
python models.py crisprHAL False ALDEx_Entropy raball Guo_SpCas9_Unique 50
python models.py crisprHAL False ALDEx_Entropy raball Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Entropy raball pTox_TevSpCas9 50


# nohup ./redo_run_all_Citro_TevSpCas9_base_models.sh > redo_run_all_Citro_TevSpCas9_base_models.out 2>&1 &
# 3062243
# redo_run_all_Citro_TevSpCas9_base_models.sh

python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Standard effect Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Standard raball Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Scale diffbtw Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Scale effect Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Scale raball Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Entropy diffbtw Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Entropy effect Citro_TevSpCas9 50
python models.py crisprHAL False ALDEx_Entropy raball Citro_TevSpCas9 50


---------------------------------------------------------------------------

# Transfer learning tests: only using Guo & Citro TevSpCas9 datasets as the base models
# ("Guo_eSpCas9" "Guo_SpCas9" "Guo_eSpCas9_Unique" "Guo_SpCas9_Unique" "Citro_TevSpCas9" "pTox_TevSpCas9" "pTox_SpCas9")


# nohup ./run_Guo_eSpCas9_base_transfer_learning.sh > run_Guo_eSpCas9_base_transfer_learning.out 2>&1 &
# 2908842
# run_Guo_eSpCas9_base_transfer_learning.sh

#!/bin/bash
declare -a arr=("Guo_SpCas9_Unique" "Citro_TevSpCas9" "pTox_TevSpCas9" "pTox_SpCas9")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard raball Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale diffbtw Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale effect Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale raball Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy raball Guo_eSpCas9 50 "$i" 50
done


# nohup ./run_Guo_eSpCas9_Unique_base_transfer_learning.sh > run_Guo_eSpCas9_Unique_base_transfer_learning.out 2>&1 &
# run_Guo_eSpCas9_Unique_base_transfer_learning.sh

#!/bin/bash
declare -a arr=("Guo_SpCas9" "Guo_SpCas9_Unique" "Citro_TevSpCas9" "pTox_TevSpCas9" "pTox_SpCas9")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard raball Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale diffbtw Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale effect Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale raball Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Guo_eSpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy raball Guo_eSpCas9_Unique 50 "$i" 50
done


# nohup ./run_Guo_SpCas9_base_transfer_learning.sh > run_Guo_SpCas9_base_transfer_learning.out 2>&1 &
# 2912075
# run_Guo_SpCas9_base_transfer_learning.sh

#!/bin/bash
declare -a arr=("Guo_eSpCas9_Unique" "Citro_TevSpCas9" "pTox_TevSpCas9" "pTox_SpCas9")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard raball Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale diffbtw Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale effect Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale raball Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy raball Guo_SpCas9 50 "$i" 50
done


# nohup ./run_Guo_SpCas9_Unique_base_transfer_learning.sh > run_Guo_SpCas9_Unique_base_transfer_learning.out 2>&1 &
# run_Guo_SpCas9_Unique_base_transfer_learning.sh

#!/bin/bash
declare -a arr=("Guo_eSpCas9" "Guo_eSpCas9_Unique" "Citro_TevSpCas9" "pTox_TevSpCas9" "pTox_SpCas9")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard raball Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale diffbtw Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale effect Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale raball Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Guo_SpCas9_Unique 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy raball Guo_SpCas9_Unique 50 "$i" 50
done


# nohup ./run_Citro_TevSpCas9_base_transfer_learning.sh > run_Citro_TevSpCas9_base_transfer_learning.out 2>&1 &
# 2914681 (had to redo base model generation due to inverse data scoring); redo: 1043126
# run_Citro_TevSpCas9_base_transfer_learning.sh

#!/bin/bash
declare -a arr=("Guo_eSpCas9" "Guo_SpCas9" "Guo_eSpCas9_Unique" "Guo_SpCas9_Unique" "pTox_TevSpCas9" "pTox_SpCas9")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard raball Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale diffbtw Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale effect Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Scale raball Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy raball Citro_TevSpCas9 50 "$i" 50
done


'''

# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------

''' TRANSFER LEARNING TESTING REDO

# nohup ./run_Guo_eSpCas9_base_TL_variation.sh > run_Guo_eSpCas9_base_TL_variation.out 2>&1 &
# 1311492
# run_Guo_eSpCas9_base_TL_variation.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_eSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Guo_eSpCas9 50 "$i" 50
done


# nohup ./run_Guo_SpCas9_base_TL_variation.sh > run_Guo_SpCas9_base_TL_variation.out 2>&1 &
# 1311954
# run_Guo_SpCas9_base_TL_variation.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "Guo_eSpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Guo_SpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Guo_SpCas9 50 "$i" 50
done


# nohup ./run_Citro_TevSpCas9_base_TL_variation.sh > run_Citro_TevSpCas9_base_TL_variation.out 2>&1 &
# 1312362
# run_Citro_TevSpCas9_base_TL_variation.sh

#!/bin/bash
declare -a arr=("Guo_eSpCas9" "Guo_SpCas9" "Guo_eSpCas9_Unique" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Standard effect Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy diffbtw Citro_TevSpCas9 50 "$i" 50
   python models.py crisprHAL False ALDEx_Entropy effect Citro_TevSpCas9 50 "$i" 50
done


'''

# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------

''' TRANSFER LEARNING TESTING REDO WITH CORRECTED OUTPUT AND CORRECTED KATG DATA

# nohup ./run_Guo_eSpCas9_base_TL_diffbtw.sh > run_Guo_eSpCas9_base_TL_diffbtw.out 2>&1 &
# 113613
# run_Guo_eSpCas9_base_TL_diffbtw.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9 50 "$i" 50
done


# nohup ./run_Guo_SpCas9_base_TL_diffbtw.sh > run_Guo_SpCas9_base_TL_diffbtw.out 2>&1 &
# 113760
# run_Guo_SpCas9_base_TL_diffbtw.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "Guo_eSpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9 50 "$i" 50
done


# nohup ./run_Citro_TevSpCas9_base_TL_diffbtw.sh > run_Citro_TevSpCas9_base_TL_diffbtw.out 2>&1 &
# 114116
# run_Citro_TevSpCas9_base_TL_diffbtw.sh

#!/bin/bash
declare -a arr=("Guo_eSpCas9" "Guo_SpCas9" "Guo_eSpCas9_Unique" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50 "$i" 50
done


'''

# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------

''' FINALLY DOING THE GUO SCORE DATA
# nohup ./run_GuoScore_base_models.sh > run_GuoScore_base_models.out 2>&1 &
# 2813476
# run_GuoScore_base_models.sh

python models.py crisprHAL True ALDEx_Standard diffbtw Guo_eSpCas9 50
python models.py crisprHAL True ALDEx_Standard diffbtw Guo_SpCas9 50
python models.py crisprHAL True ALDEx_Standard diffbtw Guo_eSpCas9_Unique 50
python models.py crisprHAL True ALDEx_Standard diffbtw Guo_SpCas9_Unique 50




# nohup ./run_GuoScore_eSpCas9_base_TL_diffbtw.sh > run_GuoScore_eSpCas9_base_TL_diffbtw.out 2>&1 &
# 1908814
# run_GuoScore_eSpCas9_base_TL_diffbtw.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL True ALDEx_Standard diffbtw Guo_eSpCas9 50 "$i" 50
done


# nohup ./run_GuoScore_SpCas9_base_TL_diffbtw.sh > run_GuoScore_SpCas9_base_TL_diffbtw.out 2>&1 &
# 1909063
# run_GuoScore_SpCas9_base_TL_diffbtw.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "Guo_eSpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL True ALDEx_Standard diffbtw Guo_SpCas9 50 "$i" 50
done

'''

# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------

''' TESTING THE SACAS9 DATA (Agrajag):
# nohup ./run_SaCas9_base_models.sh > run_SaCas9_base_models.out 2>&1 &
# 192959 [started 18 April 2024, 5PM]
# run_SaCas9_base_models.sh

python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSaCas9 50
python models.py crisprHAL_short False ALDEx_Standard diffbtw Citro_TevSaCas9 50
python models.py crisprHAL_noT False ALDEx_Standard diffbtw Citro_TevSaCas9 50
python models.py crisprHAL_noT_short False ALDEx_Standard diffbtw Citro_TevSaCas9 50
python models.py crisprHAL False ALDEx_Standard diffbtw pTox_TevSaCas9 50
python models.py crisprHAL_short False ALDEx_Standard diffbtw pTox_TevSaCas9 50
python models.py crisprHAL_noT False ALDEx_Standard diffbtw pTox_TevSaCas9 50
python models.py crisprHAL_noT_short False ALDEx_Standard diffbtw pTox_TevSaCas9 50


'''















































# ------------------------------------------------------------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------------------------------------------------------------


'''
# TRANSFER LEARNING ON KEVIN -- Major change: only 30 epochs tested
# Needs (maybe) a reinitialization of: 'export TF_GPU_ALLOCATOR=cuda_malloc_async' for proper GPU RAM usage


# nohup ./run_Guo_eSpCas9_base_TL.sh > run_Guo_eSpCas9_base_TL.out 2>&1 &
# 2456493 [started 17 April 2024, 1PM]
# run_Guo_eSpCas9_base_TL.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "pTox_TevSpCas9" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_eSpCas9 50 "$i" 30
   python models.py crisprHAL True ALDEx_Standard diffbtw Guo_eSpCas9 50 "$i" 30
   python models.py crisprHAL False ALDEx_Standard effect Guo_eSpCas9 50 "$i" 30
   python models.py crisprHAL True ALDEx_Standard effect Guo_eSpCas9 50 "$i" 30
done


# nohup ./run_Guo_SpCas9_base_TL.sh > run_Guo_SpCas9_base_TL.out 2>&1 &
# 2457001 [started 17 April 2024, 1PM]
# run_Guo_SpCas9_base_TL.sh

#!/bin/bash
declare -a arr=("Citro_TevSpCas9" "pTox_TevSpCas9" "Guo_eSpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Guo_SpCas9 50 "$i" 30
   python models.py crisprHAL True ALDEx_Standard diffbtw Guo_SpCas9 50 "$i" 30
   python models.py crisprHAL False ALDEx_Standard effect Guo_SpCas9 50 "$i" 30
   python models.py crisprHAL True ALDEx_Standard effect Guo_SpCas9 50 "$i" 30
done


# nohup ./run_Citro_TevSpCas9_base_TL.sh > run_Citro_TevSpCas9_base_TL.out 2>&1 &
# 2459432 [started 17 April 2024, 1PM]
# run_Citro_TevSpCas9_base_TL.sh

#!/bin/bash
python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50 pTox_TevSpCas9 30
python models.py crisprHAL False ALDEx_Standard effect Citro_TevSpCas9 50 pTox_TevSpCas9 30
declare -a arr=("Guo_eSpCas9" "Guo_SpCas9" "Guo_eSpCas9_Unique" "Guo_SpCas9_Unique")
for i in "${arr[@]}"
do
   python models.py crisprHAL False ALDEx_Standard diffbtw Citro_TevSpCas9 50 "$i" 30
   python models.py crisprHAL False ALDEx_Standard effect Citro_TevSpCas9 50 "$i" 30
done


'''
